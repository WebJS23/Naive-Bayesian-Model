{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义创建列表函数\n",
    "def createVocabList(dataSet):\n",
    "    #创建一个空集\n",
    "    vocabSet = set([])\n",
    "    for document in dataSet:\n",
    "        # 创建一个空集将每篇文档返回的新词集合添加到该集合中，求并集\n",
    "        vocabSet = vocabSet | set(document)\n",
    "    return list(vocabSet) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于每一个文本，返回一个和词汇表等长的向量，如，0，0，1）\n",
    "def setOfWords2Vec(vocabList, inputSet):\n",
    "    returnVec = [0]*len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] = 1\n",
    "    return returnVec\n",
    "\n",
    "def textParse(bigString):\n",
    "    '''\n",
    "    接收一个文档中内容，转换成由字母、数字组成的字符串列表\n",
    "    :param bigString:接收内容\n",
    "    :return:字符串列表\n",
    "    '''\n",
    "    reg = re.findall('\\w{3,}',bigString)\n",
    "    return [i.lower() for i in reg]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个朴素贝叶斯分类器，返回条件概率和先验概率\n",
    "def trainNB0(trainMatrix,trainCategory):\n",
    "    '''\n",
    "    计算条件概率\n",
    "    p1Vec:[p(w0|1) p(w1|1) p(w3|1) ... p(wn|1)]\n",
    "    p0Vec:[p(w0|0) p(w1|0) p(w3|0) ... p(wn|0)]\n",
    "    :param trainMatrix:训练矩阵\n",
    "    :param trainCategory:训练矩阵对应的标签\n",
    "    :return:\n",
    "    p1Vec-侮辱类的条件概率数组\n",
    "    p0Vec-非侮辱类的条件概率数组\n",
    "    pAbusive-文档属于侮辱类的概率\n",
    "    '''\n",
    "    numTrainDocs = len(trainMatrix)\n",
    "    numWords = len(trainMatrix[0])\n",
    "    pAbusive = sum(trainCategory)/float(numTrainDocs)\n",
    "    p1Vec = np.ones(numWords)\n",
    "    p0Vec = np.ones(numWords)\n",
    "    p1Demon = 2.0\n",
    "    p0Demon = 2.0\n",
    "    for i in range(numTrainDocs):\n",
    "        if trainCategory[i] == 1:\n",
    "            p1Vec += trainCategory[i]\n",
    "            p1Demon += sum(trainMatrix[i])\n",
    "        else:\n",
    "            p0Vec += trainCategory[i]\n",
    "            p0Demon += sum(trainMatrix[i])\n",
    "    p1Vec = p1Vec / p1Demon\n",
    "    p0Vec = p0Vec / p0Demon\n",
    "    return p0Vec,p1Vec,pAbusive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyNB(vec2Classify,p0Vec,p1Vec,pClass1):\n",
    "    '''\n",
    "    计算并比较文档是侮辱性和非侮辱性概率大小\n",
    "    :param vec2Classify: 待分类的文档向量\n",
    "    :param p0Vec:非侮辱类的条件概率数组\n",
    "    :param p1Vec:侮辱类的条件概率数组\n",
    "    :param pClass1:训练文档中，属于侮辱类的概率\n",
    "    :return:1-属于侮辱类，0-属于非侮辱类\n",
    "    '''\n",
    "    p1 = sum(vec2Classify * p1Vec) + np.log(pClass1)\n",
    "    p0 = sum(vec2Classify * p0Vec) + np.log(1.0 - pClass1)\n",
    "    if p1 > p0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类错误的测试集： ['linkedin', 'kerry', 'haloney', 'requested', 'add', 'you', 'connection', 'linkedin', 'peter', 'like', 'add', 'you', 'professional', 'network', 'linkedin', 'kerry', 'haloney']\n",
      "错误率：10.00%\n"
     ]
    }
   ],
   "source": [
    "def spamTest():\n",
    "    '''\n",
    "    随机选择40个文档作为训练数据，10个作为测试数据，测试朴素贝叶斯分类器效果\n",
    "    :return:无，打印错误率\n",
    "    '''\n",
    "    docList = []\n",
    "    classList = []\n",
    "    fullText = []\n",
    "    for i in range(1,26):\n",
    "        wordList = textParse(open('email/spam/%d.txt'%i,'r',encoding='ISO-8859-1').read())\n",
    "        docList.append(wordList)\n",
    "        classList.append(1)\n",
    "        wordList = textParse(open('email/ham/%d.txt'%i,'r',encoding='ISO-8859-1').read())\n",
    "        docList.append(wordList)\n",
    "        classList.append(0)\n",
    "    vocalList = createVocabList(docList)\n",
    "    trainingSet = list(range(50))\n",
    "    testSet = []\n",
    "    for i in range(10):\n",
    "        randIndex = int(random.uniform(0,len(trainingSet)))\n",
    "        testSet.append(trainingSet[randIndex])\n",
    "        del trainingSet[randIndex]\n",
    "    trainMat = []\n",
    "    trainingClasses = []\n",
    "    for docIndex in trainingSet:\n",
    "        trainMat.append(setOfWords2Vec(vocalList,docList[docIndex]))\n",
    "        trainingClasses.append(classList[docIndex])\n",
    "    p0V,p1V,pSpam = trainNB0(np.array(trainMat),np.array(trainingClasses))\n",
    "    errorCount = 0\n",
    "    for docIndex in testSet:\n",
    "        wordVector = setOfWords2Vec(vocalList,docList[docIndex])\n",
    "        if classifyNB(np.array(wordVector),p0V,p1V,pSpam) != classList[docIndex]:\n",
    "            errorCount += 1\n",
    "            print(\"分类错误的测试集：\",docList[docIndex])\n",
    "    print(\"错误率：%.2f%%\"%(float(errorCount)/len(testSet)*100))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    spamTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:FML] *",
   "language": "python",
   "name": "conda-env-FML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
